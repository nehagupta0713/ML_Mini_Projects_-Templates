{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, I have compared the results of content based and collaborative recommendation systems. I have used some of the ideas from this kernel:-\n",
    "https://www.kaggle.com/fabiendaniel/film-recommendation-engine\n",
    "This notebook can be used as a template for recommendation engine implementation in Python.\n",
    "I have used the Amazon Book Review Dataset that can be found here.\n",
    "http://jmcauley.ucsd.edu/data/amazon/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "import timeit\n",
    "import time\n",
    "import resource"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path = r\"C:\\Users\\Neha\\Project_Files\\Old_Ipynb_Files\\Books_5.json\"\n",
    "#c = pd.read_json(\"/home/science/small\",orient=\"columns\")\n",
    "\n",
    "#customers_json = pd.read_json('small')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def parse(path):\n",
    "  g = open(path, 'rb')\n",
    "  for l in g:\n",
    "    yield eval(l)\n",
    "\n",
    "def getDF(path):\n",
    "  i = 0\n",
    "  df = {}\n",
    "  for d in parse(path):\n",
    "    df[i] = d\n",
    "    i += 1\n",
    "  return pd.DataFrame.from_dict(df, orient='index')\n",
    "\n",
    "#def f(row):\n",
    "    #if (row.overall == 4 or row.overall == 5):\n",
    "        #val = 3\n",
    "    #elif (row.overall ==3):\n",
    "        #val = 2\n",
    "    #else:\n",
    "        #val = 1\n",
    "    #return val\n",
    "\n",
    "\n",
    "df = getDF(path)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop('reviewerName', 1)\n",
    "df = df.drop('helpful', 1)\n",
    "#df = df.drop('summary', 1)\n",
    "df = df.drop('unixReviewTime', 1)\n",
    "#df = df.drop('reviewerID', 1)\n",
    "#df = df.drop('asin', 1)\n",
    "df = df.drop('reviewTime', 1)\n",
    "#df['rating'] = df.apply(f, axis=1)\n",
    "#df = df.drop('overall', 1)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Collaborative Filtering\n",
    "ratings_matrix = df.pivot_table(index=['asin'],columns=['reviewerID'],values='overall').reset_index(drop=True)\n",
    "ratings_matrix.fillna( 0, inplace = True )\n",
    "movie_similarity=cosine_similarity(ratings_matrix)\n",
    "np.fill_diagonal( movie_similarity, 0 ) \n",
    "movie_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time taken by train function 471.379958152771\n",
      "memory used by train function 1033868\n"
     ]
    }
   ],
   "source": [
    "#### Sentiment Analysis\n",
    "trainX,testX,trainY,testY = train_test_split(df['reviewText'],df['rating'], test_size = 0.2, random_state = 10)\n",
    "cv = CountVectorizer()\n",
    "\n",
    "start_mem = resource.getrusage(resource.RUSAGE_SELF).ru_maxrss\n",
    "t = time.time()\n",
    "cv.fit(trainX)\n",
    "trainX_cv = cv.transform(trainX)\n",
    "testX_cv = cv.transform(testX)\n",
    "model = MultinomialNB()\n",
    "model.fit(trainX_cv,trainY)\n",
    "\n",
    "elapsed_time = time.time() - t\n",
    "mem_used = resource.getrusage(resource.RUSAGE_SELF).ru_maxrss - start_mem\n",
    "\n",
    "print(\"time taken by train function\",(elapsed_time))\n",
    "print(\"memory used by train function\",(mem_used))\n",
    "cv_score = accuracy_score(testY,model.predict(testX_cv))\n",
    "print(\"cv score\", (cv_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.80130000000000001"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##### Content Based Recommendation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
